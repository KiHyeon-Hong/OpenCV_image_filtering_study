{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>202140090-홍기현-Assignment3</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple neural network with 3 hidden layers.\n",
    "# Activation function for each layer is sigmoid, and final output is produced using softmax.\n",
    "# A file for reading mnist is provided. Download \"mnist.py\" into the working directory.\n",
    "# Fill in the * marked part and try to get the final accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>필요 모듈 import</h3>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mnist import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Activation Function 구현</h3>\n",
    "<hr>\n",
    "<h4>Softmax</h4>\n",
    "\n",
    "- 여러개의 출력을 지수 함수를 적용하여 전체 비율로 나눈다.\n",
    "- 이를 통하여 전체 출력의 합은 1이되며, 큰 값은 더욱 크게, 작은 값은 더욱 작게 변한다.\n",
    "\n",
    "<br>\n",
    "<h4>Sigmoid</h4>\n",
    "\n",
    "- Binary 출력에서 0~1 사이의 값으로 변환시킨다.\n",
    "- 예를 들어 0에서는 0.5를 갖으며, 음수에서는 0 ~ 0.5, 양수에서는 0.5 ~ 1 사이의 값이다.\n",
    "- 이를 통하여 0.5를 기준으로 이진 분류가 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        c = np.max(x)\n",
    "        x = np.exp(x - c)\n",
    "    x = x - np.max(x) # handle overflow\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "                              \n",
    "                              \n",
    "def sigmoid(x):\n",
    "    x = np.exp(-x)\n",
    "    return 1 / (1 + x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<h3>그 외 기능 구현</h3>\n",
    "<br>\n",
    "\n",
    "<h4>get_data() 메소드</h4>\n",
    "\n",
    "- 서버 문제로 다운로드 코드가 작동하지 않아 직접 다운 후 수행하였다.\n",
    "- 학습 데이터는 사용하지 않으며, 이미 학습된 가중치로 성능을 평가하는 코드를 작성한다.\n",
    "\n",
    "<br>\n",
    "<h4>init_network() 메소드</h4>\n",
    "\n",
    "- 미리 학습해놓은 가중치를 읽어와 network로 반환하는 메소드\n",
    "\n",
    "<br>\n",
    "<h4>predict() 메소드</h4>\n",
    "\n",
    "- 가중치와 bias가 저장된 network와 예측할 데이터를 파라매터로 받아 예측을 수행하는 메소드\n",
    "- 은닉층은 2개, 그리고 출력층으로 이루어져 있으며, 각 은닉층은 0~1 사이의 값을 반환하는 sigmoid를, 출력층은 여러 입력에서 하나의 결과를 출력하기 위해 softmax를 Activation Function으로 이용\n",
    "- 각 층에서 예측을 하는 식은 <strong>결과 = (가중치 * 입력값) + 바이어스</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    # 가중치를 계산하고 바이어스를 더함\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    # activation Function 적용\n",
    "    z1 = sigmoid(a1)\n",
    "\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<h3>예측 수행하기</h3>\n",
    "\n",
    "- get_data()를 통해 x에 테스트 데이터를, t에 테스트 데이터에 대한 정답을 반환받는다.\n",
    "- init_network()를 통해 미리 학습한 가중치를 반환받는다.\n",
    "- accuracy_cnt 변수는 정답을 맞출 때마다 1 증가시킨다.\n",
    "\n",
    "- predict() 메소드를 통해 학습된 모델이 테스트 데이터를 어떻게 예측하는지 받는다.\n",
    "- softmax 활성화 함수의 결과이므로, 이 중 최대값이 모델이 실제로 예측한 값이다. 따라서, argmax()를 적용하여 최대값을 출력한다.\n",
    "- 만약, 예측값이 정답괴 일치한다면 accuracy_cnt를 1 증가시킨다.\n",
    "\n",
    "- 최종 결과는 정답을 맞춘 정답률이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "\n",
    "network = init_network()\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # predict을 통해 각각의 테스트 데이터의 예측값을 구함\n",
    "    y = predict(network, x[i])\n",
    "    # 예측값의 최대값이 모델이 예측한 결과\n",
    "    p = np.argmax(y)\n",
    "    \n",
    "    # 만약 예측값이 정답과 같다면 Accuracy_cnt를 1증가\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "# 전체 테스트 데이터의 개수 중 정답을 맞춤 비율을 출력\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
